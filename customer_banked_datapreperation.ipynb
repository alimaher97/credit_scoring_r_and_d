{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15ab47bf",
   "metadata": {},
   "source": [
    "# Banked Customer Data Preparation\n",
    "This notebook prepares the banked customer dataset for modeling and segmentation.\n",
    "\n",
    "It performs the following steps:\n",
    "- Load source data from `credit_report (1).xlsx`.\n",
    "- Filter to Banked customers and exclude special programs.\n",
    "- Run data quality checks (missing values, duplicates, outliers, business rules).\n",
    "- Clean data (deduplicate, cap invalid/extreme values, impute selective fields).\n",
    "- Create the binary target from `customer_bucket` (0=Good, 1=Bad).\n",
    "- Assemble the final features dataframe and save artifacts.\n",
    "\n",
    "Inputs:\n",
    "- `credit_report (1).xlsx`\n",
    "\n",
    "Outputs:\n",
    "- `banked_customer_segmentation_final.csv`\n",
    "- `banked_dataset_documentation.json`\n",
    "- `dataset_summary_report.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "648a7feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ffa18241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "df = pd.read_excel(\"credit_report (1).xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f4c3ec40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_backup =  df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38ca6e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>national_id</th>\n",
       "      <th>credit_limit</th>\n",
       "      <th>due_principal</th>\n",
       "      <th>customer_bucket</th>\n",
       "      <th>onboarding_merchant</th>\n",
       "      <th>first_transaction_merchant</th>\n",
       "      <th>rank</th>\n",
       "      <th>limit_source</th>\n",
       "      <th>special_program_flag</th>\n",
       "      <th>has_past_credit_flag</th>\n",
       "      <th>income_delta_percentage</th>\n",
       "      <th>income_delta_tier</th>\n",
       "      <th>income_delta_score</th>\n",
       "      <th>age</th>\n",
       "      <th>age_score</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>marital_status_score</th>\n",
       "      <th>jobtitle_category</th>\n",
       "      <th>jobtitle_score</th>\n",
       "      <th>address_category</th>\n",
       "      <th>address_score</th>\n",
       "      <th>gender</th>\n",
       "      <th>gender_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237293</td>\n",
       "      <td>28302022102615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fawry Plus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>13.1640</td>\n",
       "      <td>Married</td>\n",
       "      <td>14.6048</td>\n",
       "      <td>D</td>\n",
       "      <td>30.4325</td>\n",
       "      <td>C</td>\n",
       "      <td>23.4765</td>\n",
       "      <td>MALE</td>\n",
       "      <td>20.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>237294</td>\n",
       "      <td>28506300100399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fawry Plus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "      <td>15.5774</td>\n",
       "      <td>Married</td>\n",
       "      <td>14.6048</td>\n",
       "      <td>D</td>\n",
       "      <td>30.4325</td>\n",
       "      <td>A</td>\n",
       "      <td>17.3900</td>\n",
       "      <td>MALE</td>\n",
       "      <td>20.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>237295</td>\n",
       "      <td>25104210300141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fawry Plus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74</td>\n",
       "      <td>9.6536</td>\n",
       "      <td>Single</td>\n",
       "      <td>16.9520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>15.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>237296</td>\n",
       "      <td>29305050104961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Union Stores</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>16.3453</td>\n",
       "      <td>Married</td>\n",
       "      <td>14.6048</td>\n",
       "      <td>D</td>\n",
       "      <td>30.4325</td>\n",
       "      <td>B</td>\n",
       "      <td>19.9985</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>15.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>237297</td>\n",
       "      <td>28911010107839</td>\n",
       "      <td>5300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fawry Plus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Banked</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>67.963354</td>\n",
       "      <td>8.0</td>\n",
       "      <td>129.679634</td>\n",
       "      <td>35</td>\n",
       "      <td>16.0162</td>\n",
       "      <td>Married</td>\n",
       "      <td>14.6048</td>\n",
       "      <td>D</td>\n",
       "      <td>30.4325</td>\n",
       "      <td>C</td>\n",
       "      <td>23.4765</td>\n",
       "      <td>MALE</td>\n",
       "      <td>20.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>237298</td>\n",
       "      <td>29812152203199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Connect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>17.2229</td>\n",
       "      <td>Single</td>\n",
       "      <td>16.9520</td>\n",
       "      <td>D</td>\n",
       "      <td>30.4325</td>\n",
       "      <td>E</td>\n",
       "      <td>30.4325</td>\n",
       "      <td>MALE</td>\n",
       "      <td>20.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>237299</td>\n",
       "      <td>26708180102656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Connect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57</td>\n",
       "      <td>11.5185</td>\n",
       "      <td>Married</td>\n",
       "      <td>14.6048</td>\n",
       "      <td>D</td>\n",
       "      <td>30.4325</td>\n",
       "      <td>B</td>\n",
       "      <td>19.9985</td>\n",
       "      <td>MALE</td>\n",
       "      <td>20.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>237300</td>\n",
       "      <td>28301300100924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Connect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>13.1640</td>\n",
       "      <td>Married</td>\n",
       "      <td>14.6048</td>\n",
       "      <td>D</td>\n",
       "      <td>30.4325</td>\n",
       "      <td>D</td>\n",
       "      <td>26.9545</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>15.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>237301</td>\n",
       "      <td>29601102101092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Union Stores</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>16.8938</td>\n",
       "      <td>Married</td>\n",
       "      <td>14.6048</td>\n",
       "      <td>A</td>\n",
       "      <td>17.3900</td>\n",
       "      <td>A</td>\n",
       "      <td>17.3900</td>\n",
       "      <td>MALE</td>\n",
       "      <td>20.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>237302</td>\n",
       "      <td>28210240103117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Connect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>13.1640</td>\n",
       "      <td>Single</td>\n",
       "      <td>16.9520</td>\n",
       "      <td>D</td>\n",
       "      <td>30.4325</td>\n",
       "      <td>A</td>\n",
       "      <td>17.3900</td>\n",
       "      <td>MALE</td>\n",
       "      <td>20.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>237303</td>\n",
       "      <td>28802232200698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fawry Plus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "      <td>15.7968</td>\n",
       "      <td>Single</td>\n",
       "      <td>16.9520</td>\n",
       "      <td>A</td>\n",
       "      <td>17.3900</td>\n",
       "      <td>E</td>\n",
       "      <td>30.4325</td>\n",
       "      <td>MALE</td>\n",
       "      <td>20.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>237304</td>\n",
       "      <td>27709012105453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Star Phone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47</td>\n",
       "      <td>12.6155</td>\n",
       "      <td>Married</td>\n",
       "      <td>14.6048</td>\n",
       "      <td>D</td>\n",
       "      <td>30.4325</td>\n",
       "      <td>D</td>\n",
       "      <td>26.9545</td>\n",
       "      <td>MALE</td>\n",
       "      <td>20.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>237305</td>\n",
       "      <td>26707170200378</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SETTLED</td>\n",
       "      <td>ElShennawy</td>\n",
       "      <td>Al Masria Groub</td>\n",
       "      <td>2</td>\n",
       "      <td>UnBanked</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-18.367347</td>\n",
       "      <td>2.0</td>\n",
       "      <td>99.816327</td>\n",
       "      <td>57</td>\n",
       "      <td>11.5185</td>\n",
       "      <td>Married</td>\n",
       "      <td>14.6048</td>\n",
       "      <td>D</td>\n",
       "      <td>30.4325</td>\n",
       "      <td>B</td>\n",
       "      <td>19.9985</td>\n",
       "      <td>MALE</td>\n",
       "      <td>20.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>237305</td>\n",
       "      <td>26707170200378</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SETTLED</td>\n",
       "      <td>ElShennawy</td>\n",
       "      <td>ElShennawy</td>\n",
       "      <td>2</td>\n",
       "      <td>UnBanked</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-18.367347</td>\n",
       "      <td>2.0</td>\n",
       "      <td>99.816327</td>\n",
       "      <td>57</td>\n",
       "      <td>11.5185</td>\n",
       "      <td>Married</td>\n",
       "      <td>14.6048</td>\n",
       "      <td>D</td>\n",
       "      <td>30.4325</td>\n",
       "      <td>B</td>\n",
       "      <td>19.9985</td>\n",
       "      <td>MALE</td>\n",
       "      <td>20.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>237306</td>\n",
       "      <td>26201191900298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Select</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63</td>\n",
       "      <td>10.8603</td>\n",
       "      <td>Married</td>\n",
       "      <td>14.6048</td>\n",
       "      <td>A</td>\n",
       "      <td>17.3900</td>\n",
       "      <td>B</td>\n",
       "      <td>19.9985</td>\n",
       "      <td>MALE</td>\n",
       "      <td>20.547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    customer_id     national_id  credit_limit  due_principal customer_bucket  \\\n",
       "0        237293  28302022102615           0.0            0.0             NaN   \n",
       "1        237294  28506300100399           0.0            0.0             NaN   \n",
       "2        237295  25104210300141           0.0            0.0             NaN   \n",
       "3        237296  29305050104961           0.0            0.0             NaN   \n",
       "4        237297  28911010107839        5300.0            0.0             NaN   \n",
       "5        237298  29812152203199           0.0            0.0             NaN   \n",
       "6        237299  26708180102656           0.0            0.0             NaN   \n",
       "7        237300  28301300100924           0.0            0.0             NaN   \n",
       "8        237301  29601102101092           0.0            0.0             NaN   \n",
       "9        237302  28210240103117           0.0            0.0             NaN   \n",
       "10       237303  28802232200698           0.0            0.0             NaN   \n",
       "11       237304  27709012105453           0.0            0.0             NaN   \n",
       "12       237305  26707170200378        9000.0            0.0         SETTLED   \n",
       "13       237305  26707170200378        9000.0            0.0         SETTLED   \n",
       "14       237306  26201191900298           0.0            0.0             NaN   \n",
       "\n",
       "   onboarding_merchant first_transaction_merchant  rank limit_source  \\\n",
       "0           Fawry Plus                        NaN     3          NaN   \n",
       "1           Fawry Plus                        NaN     2          NaN   \n",
       "2           Fawry Plus                        NaN     4          NaN   \n",
       "3         Union Stores                        NaN     3          NaN   \n",
       "4           Fawry Plus                        NaN     3       Banked   \n",
       "5              Connect                        NaN     4          NaN   \n",
       "6              Connect                        NaN     2          NaN   \n",
       "7              Connect                        NaN     2          NaN   \n",
       "8         Union Stores                        NaN     1          NaN   \n",
       "9              Connect                        NaN     2          NaN   \n",
       "10          Fawry Plus                        NaN     2          NaN   \n",
       "11          Star Phone                        NaN     2          NaN   \n",
       "12          ElShennawy            Al Masria Groub     2     UnBanked   \n",
       "13          ElShennawy                 ElShennawy     2     UnBanked   \n",
       "14              Select                        NaN     1          NaN   \n",
       "\n",
       "    special_program_flag  has_past_credit_flag  income_delta_percentage  \\\n",
       "0                  False                 False                      NaN   \n",
       "1                  False                 False                      NaN   \n",
       "2                  False                 False                      NaN   \n",
       "3                  False                 False                      NaN   \n",
       "4                  False                  True                67.963354   \n",
       "5                  False                 False                      NaN   \n",
       "6                  False                 False                      NaN   \n",
       "7                  False                 False                      NaN   \n",
       "8                  False                 False                      NaN   \n",
       "9                  False                 False                      NaN   \n",
       "10                 False                 False                      NaN   \n",
       "11                 False                 False                      NaN   \n",
       "12                 False                 False               -18.367347   \n",
       "13                 False                 False               -18.367347   \n",
       "14                 False                 False                      NaN   \n",
       "\n",
       "    income_delta_tier  income_delta_score  age  age_score marital_status  \\\n",
       "0                 NaN                 NaN   42    13.1640        Married   \n",
       "1                 NaN                 NaN   39    15.5774        Married   \n",
       "2                 NaN                 NaN   74     9.6536         Single   \n",
       "3                 NaN                 NaN   32    16.3453        Married   \n",
       "4                 8.0          129.679634   35    16.0162        Married   \n",
       "5                 NaN                 NaN   26    17.2229         Single   \n",
       "6                 NaN                 NaN   57    11.5185        Married   \n",
       "7                 NaN                 NaN   42    13.1640        Married   \n",
       "8                 NaN                 NaN   29    16.8938        Married   \n",
       "9                 NaN                 NaN   42    13.1640         Single   \n",
       "10                NaN                 NaN   37    15.7968         Single   \n",
       "11                NaN                 NaN   47    12.6155        Married   \n",
       "12                2.0           99.816327   57    11.5185        Married   \n",
       "13                2.0           99.816327   57    11.5185        Married   \n",
       "14                NaN                 NaN   63    10.8603        Married   \n",
       "\n",
       "    marital_status_score jobtitle_category  jobtitle_score address_category  \\\n",
       "0                14.6048                 D         30.4325                C   \n",
       "1                14.6048                 D         30.4325                A   \n",
       "2                16.9520               NaN             NaN              NaN   \n",
       "3                14.6048                 D         30.4325                B   \n",
       "4                14.6048                 D         30.4325                C   \n",
       "5                16.9520                 D         30.4325                E   \n",
       "6                14.6048                 D         30.4325                B   \n",
       "7                14.6048                 D         30.4325                D   \n",
       "8                14.6048                 A         17.3900                A   \n",
       "9                16.9520                 D         30.4325                A   \n",
       "10               16.9520                 A         17.3900                E   \n",
       "11               14.6048                 D         30.4325                D   \n",
       "12               14.6048                 D         30.4325                B   \n",
       "13               14.6048                 D         30.4325                B   \n",
       "14               14.6048                 A         17.3900                B   \n",
       "\n",
       "    address_score  gender  gender_score  \n",
       "0         23.4765    MALE        20.547  \n",
       "1         17.3900    MALE        20.547  \n",
       "2             NaN  FEMALE        15.220  \n",
       "3         19.9985  FEMALE        15.220  \n",
       "4         23.4765    MALE        20.547  \n",
       "5         30.4325    MALE        20.547  \n",
       "6         19.9985    MALE        20.547  \n",
       "7         26.9545  FEMALE        15.220  \n",
       "8         17.3900    MALE        20.547  \n",
       "9         17.3900    MALE        20.547  \n",
       "10        30.4325    MALE        20.547  \n",
       "11        26.9545    MALE        20.547  \n",
       "12        19.9985    MALE        20.547  \n",
       "13        19.9985    MALE        20.547  \n",
       "14        19.9985    MALE        20.547  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set pandas display options to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f84a0438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (427116, 24)\n",
      "Filtered dataset shape (Banked only): (40939, 24)\n",
      "\n",
      "Unique values in limit_source (original):\n",
      "limit_source\n",
      "UnBanked    90017\n",
      "Banked      40939\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Filter for Banked customers only\n",
    "df = df[df['limit_source'] == 'Banked'].copy()\n",
    "print(f\"Original dataset shape: {df_backup.shape}\")\n",
    "print(f\"Filtered dataset shape (Banked only): {df.shape}\")\n",
    "print(f\"\\nUnique values in limit_source (original):\")\n",
    "print(df_backup['limit_source'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e62e202e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape: (40939, 24)\n",
      "\n",
      "df columns: ['customer_id', 'national_id', 'credit_limit', 'due_principal', 'customer_bucket', 'onboarding_merchant', 'first_transaction_merchant', 'rank', 'limit_source', 'special_program_flag', 'has_past_credit_flag', 'income_delta_percentage', 'income_delta_tier', 'income_delta_score', 'age', 'age_score', 'marital_status', 'marital_status_score', 'jobtitle_category', 'jobtitle_score', 'address_category', 'address_score', 'gender', 'gender_score']\n",
      "\n",
      "First 5 rows of df:\n",
      "    customer_id     national_id  credit_limit  due_principal customer_bucket  \\\n",
      "4        237297  28911010107839        5300.0            0.0             NaN   \n",
      "75       237365  27112090104734        8600.0            0.0        BUCKET-7   \n",
      "79       237369  28506010102517        6200.0            0.0         SETTLED   \n",
      "80       237369  28506010102517        6200.0            0.0         SETTLED   \n",
      "83       237371  27602201500496       23800.0            0.0             NaN   \n",
      "\n",
      "   onboarding_merchant first_transaction_merchant  rank limit_source  \\\n",
      "4           Fawry Plus                        NaN     3       Banked   \n",
      "75          Fawry Plus                   Spinneys     3       Banked   \n",
      "79               Byoot                      Byoot     2       Banked   \n",
      "80               Byoot                       Mado     2       Banked   \n",
      "83      Shabana Stores                        NaN     2       Banked   \n",
      "\n",
      "    special_program_flag  has_past_credit_flag  income_delta_percentage  \\\n",
      "4                  False                  True                67.963354   \n",
      "75                 False                  True                25.515398   \n",
      "79                 False                  True                12.753936   \n",
      "80                 False                  True                12.753936   \n",
      "83                 False                  True                25.960348   \n",
      "\n",
      "    income_delta_tier  income_delta_score  age  age_score marital_status  \\\n",
      "4                 8.0          129.679634   35    16.0162        Married   \n",
      "75                5.0          100.255154   53    11.9573        Married   \n",
      "79                4.0          100.127539   40    15.4677         Single   \n",
      "80                4.0          100.127539   40    15.4677         Single   \n",
      "83                5.0          100.259603   49    12.3961        Married   \n",
      "\n",
      "    marital_status_score jobtitle_category  jobtitle_score address_category  \\\n",
      "4                14.6048                 D         30.4325                C   \n",
      "75               14.6048                 D         30.4325                B   \n",
      "79               16.9520                 A         17.3900                C   \n",
      "80               16.9520                 A         17.3900                C   \n",
      "83               14.6048                 A         17.3900                E   \n",
      "\n",
      "    address_score gender  gender_score  \n",
      "4         23.4765   MALE        20.547  \n",
      "75        19.9985   MALE        20.547  \n",
      "79        23.4765   MALE        20.547  \n",
      "80        23.4765   MALE        20.547  \n",
      "83        30.4325   MALE        20.547  \n"
     ]
    }
   ],
   "source": [
    "# Filter for none special programmes\n",
    "df = df[df['special_program_flag'] != 'True'].copy()\n",
    "print(\"df shape:\", df.shape)\n",
    "print(\"\\ndf columns:\", df.columns.tolist())\n",
    "print(\"\\nFirst 5 rows of df:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "940a4915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank\n",
      "1     6541\n",
      "2    21589\n",
      "3    12746\n",
      "4       63\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# print original rank distribution\n",
    "print(df['rank'].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e4b6ca76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Banked rank distribution:\n",
      "Shape before filtering by credit limit: (40939, 24)\n",
      "Shape after filtering by credit limit: (40315, 24)\n"
     ]
    }
   ],
   "source": [
    "# remove customers with no credit limit or credit limit = zero\n",
    "print(f\"\\nBanked rank distribution:\")\n",
    "print(f\"Shape before filtering by credit limit: {df.shape}\")\n",
    "df = df[df[\"credit_limit\"].notnull() & (df[\"credit_limit\"] > 0)]\n",
    "print(f\"Shape after filtering by credit limit: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "db10306c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape before filtering by customer_bucket: (40315, 24)\n",
      "Shape after filtering by customer_bucket: (24973, 24)\n"
     ]
    }
   ],
   "source": [
    "# remove customers with null customer_bucket as they might got limit but no loans\n",
    "print(f\"\\nShape before filtering by customer_bucket: {df.shape}\")\n",
    "df = df[df[\"customer_bucket\"].notnull()]\n",
    "print(f\"Shape after filtering by customer_bucket: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a15d6046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records with CANCELLED/CANCELLED-PARTIAL-REFUND: 592\n",
      "Shape after removing CANCELLED/CANCELLED-PARTIAL-REFUND: (24381, 24)\n"
     ]
    }
   ],
   "source": [
    "# remove CANCELLED/CANCELLED-PARTIAL-REFUND; should be removed\n",
    "cancelled_counts = df['customer_bucket'].isin(['CANCELLED', 'CANCELLED-PARTIAL-REFUND']).sum()\n",
    "print(f\"Records with CANCELLED/CANCELLED-PARTIAL-REFUND: {cancelled_counts}\")\n",
    "df = df[~df['customer_bucket'].isin(['CANCELLED', 'CANCELLED-PARTIAL-REFUND'])].copy()\n",
    "print(f\"Shape after removing CANCELLED/CANCELLED-PARTIAL-REFUND: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8f6b8939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24381, 24)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9d6714",
   "metadata": {},
   "source": [
    "##### data quality check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d86748da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA QUALITY CHECK\n",
      "============================================================\n",
      "Dataset shape: (24381, 24)\n",
      "Number of unique customers: 18333\n",
      "Total records: 24381\n",
      "Average records per customer: 1.33\n"
     ]
    }
   ],
   "source": [
    "# Data Quality Check - Basic Info\n",
    "print(\"=\"*60)\n",
    "print(\"DATA QUALITY CHECK\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Number of unique customers: {df['customer_id'].nunique()}\")\n",
    "print(f\"Total records: {len(df)}\")\n",
    "print(f\"Average records per customer: {len(df) / df['customer_id'].nunique():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ca67a854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "MISSING VALUES ANALYSIS\n",
      "========================================\n",
      "                         Missing_Count  Missing_Percentage\n",
      "income_delta_tier                   21            0.086133\n",
      "income_delta_score                  21            0.086133\n",
      "income_delta_percentage             21            0.086133\n"
     ]
    }
   ],
   "source": [
    "# Data Quality Check - Missing Values\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"MISSING VALUES ANALYSIS\")\n",
    "print(\"=\"*40)\n",
    "missing_summary = df.isnull().sum()\n",
    "missing_pct = (missing_summary / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing_Count': missing_summary,\n",
    "    'Missing_Percentage': missing_pct\n",
    "}).sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "print(missing_df[missing_df['Missing_Count'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b931ed0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "DUPLICATE ANALYSIS\n",
      "========================================\n",
      "Total duplicate rows: 0\n",
      "Duplicate customers (same customer_id): 6048\n",
      "Duplicate national_ids: 6048\n"
     ]
    }
   ],
   "source": [
    "# Data Quality Check - Duplicates\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"DUPLICATE ANALYSIS\")\n",
    "print(\"=\"*40)\n",
    "print(f\"Total duplicate rows: {df.duplicated().sum()}\")\n",
    "print(f\"Duplicate customers (same customer_id): {df.duplicated(subset=['customer_id']).sum()}\")\n",
    "print(f\"Duplicate national_ids: {df.duplicated(subset=['national_id']).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "03431c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "CATEGORICAL VARIABLES DISTRIBUTION\n",
      "========================================\n",
      "\n",
      "CUSTOMER_BUCKET:\n",
      "customer_bucket\n",
      "CURRENT                      11819\n",
      "SETTLED-PAIDOFF               4562\n",
      "SETTLED                       3465\n",
      "BUCKET-1                      1781\n",
      "BUCKET-2                       865\n",
      "BUCKET-7                       834\n",
      "BUCKET-3                       402\n",
      "BUCKET-4                       277\n",
      "BUCKET-5                       206\n",
      "BUCKET-6                       131\n",
      "SETTLE-CHARGE-OFF               22\n",
      "PARTIAL-SETTLE-CHARGE-OFF       17\n",
      "Name: count, dtype: int64\n",
      "Unique values: 12\n",
      "\n",
      "RANK:\n",
      "rank\n",
      "2    13292\n",
      "3     7427\n",
      "1     3614\n",
      "4       48\n",
      "Name: count, dtype: int64\n",
      "Unique values: 4\n",
      "\n",
      "SPECIAL_PROGRAM_FLAG:\n",
      "special_program_flag\n",
      "False    24209\n",
      "True       172\n",
      "Name: count, dtype: int64\n",
      "Unique values: 2\n",
      "\n",
      "MARITAL_STATUS:\n",
      "marital_status\n",
      "Married     16472\n",
      "Single       5007\n",
      "Widowed      2135\n",
      "Divorced      767\n",
      "Name: count, dtype: int64\n",
      "Unique values: 4\n",
      "\n",
      "JOBTITLE_CATEGORY:\n",
      "jobtitle_category\n",
      "D    13167\n",
      "A    11214\n",
      "Name: count, dtype: int64\n",
      "Unique values: 2\n",
      "\n",
      "ADDRESS_CATEGORY:\n",
      "address_category\n",
      "B    9547\n",
      "A    6421\n",
      "C    4445\n",
      "D    2565\n",
      "E    1403\n",
      "Name: count, dtype: int64\n",
      "Unique values: 5\n",
      "\n",
      "GENDER:\n",
      "gender\n",
      "MALE      16416\n",
      "FEMALE     7965\n",
      "Name: count, dtype: int64\n",
      "Unique values: 2\n",
      "\n",
      "INCOME_DELTA_TIER:\n",
      "income_delta_tier\n",
      "11.0    5773\n",
      "4.0     2573\n",
      "3.0     2547\n",
      "1.0     2279\n",
      "5.0     2164\n",
      "6.0     1919\n",
      "2.0     1819\n",
      "7.0     1769\n",
      "8.0     1454\n",
      "9.0     1277\n",
      "10.0     786\n",
      "Name: count, dtype: int64\n",
      "Unique values: 11\n"
     ]
    }
   ],
   "source": [
    "# Data Quality Check - Categorical Variables\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"CATEGORICAL VARIABLES DISTRIBUTION\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "categorical_cols = ['customer_bucket', 'rank', 'special_program_flag', 'marital_status', \n",
    "                   'jobtitle_category', 'address_category', 'gender', 'income_delta_tier']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        print(f\"\\n{col.upper()}:\")\n",
    "        print(df[col].value_counts())\n",
    "        print(f\"Unique values: {df[col].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a541b374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "NUMERICAL VARIABLES SUMMARY\n",
      "========================================\n",
      "        credit_limit  due_principal  income_delta_percentage           age\n",
      "count   24381.000000   24381.000000             24360.000000  24381.000000\n",
      "mean    21431.755875       2.544193                78.008949     41.375210\n",
      "std     17568.910503      47.334097               170.152606      9.855173\n",
      "min      1000.000000       0.000000               -90.290845     21.000000\n",
      "25%      8200.000000       0.000000                -2.576847     33.000000\n",
      "50%     16000.000000       0.000000                35.954932     41.000000\n",
      "75%     32500.000000       0.000000                98.428669     49.000000\n",
      "max    200000.000000    2195.470000              2500.000000     64.000000\n",
      "\n",
      "========================================\n",
      "OUTLIER DETECTION (Values beyond 3 standard deviations)\n",
      "========================================\n",
      "credit_limit: 237 outliers (0.97%)\n",
      "due_principal: 100 outliers (0.41%)\n",
      "income_delta_percentage: 359 outliers (1.47%)\n",
      "age: 0 outliers (0.00%)\n"
     ]
    }
   ],
   "source": [
    "# Data Quality Check - Numerical Variables\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"NUMERICAL VARIABLES SUMMARY\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "numerical_cols = ['credit_limit', 'due_principal', 'income_delta_percentage', 'age']\n",
    "print(df[numerical_cols].describe())\n",
    "\n",
    "# Check for outliers\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"OUTLIER DETECTION (Values beyond 3 standard deviations)\")\n",
    "print(\"=\"*40)\n",
    "for col in numerical_cols:\n",
    "    if col in df.columns:\n",
    "        mean_val = df[col].mean()\n",
    "        std_val = df[col].std()\n",
    "        outliers = df[(df[col] < mean_val - 3*std_val) | (df[col] > mean_val + 3*std_val)]\n",
    "        print(f\"{col}: {len(outliers)} outliers ({len(outliers)/len(df)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6500654b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "BUSINESS LOGIC VALIDATION\n",
      "========================================\n",
      "Records with negative credit_limit: 0\n",
      "Records with invalid age (< 18 or > 100): 0\n",
      "Records with extreme income_delta_percentage (< -100% or > 500%): 523\n",
      "Records where due_principal > credit_limit: 0\n"
     ]
    }
   ],
   "source": [
    "# Data Quality Check - Business Logic Validation\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"BUSINESS LOGIC VALIDATION\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Check for negative credit limits\n",
    "negative_limits = df[df['credit_limit'] < 0]\n",
    "print(f\"Records with negative credit_limit: {len(negative_limits)}\")\n",
    "\n",
    "# Check age ranges\n",
    "invalid_ages = df[(df['age'] < 18) | (df['age'] > 100)]\n",
    "print(f\"Records with invalid age (< 18 or > 100): {len(invalid_ages)}\")\n",
    "\n",
    "# Check income delta percentage extreme values\n",
    "extreme_income = df[(df['income_delta_percentage'] < -100) | (df['income_delta_percentage'] > 500)]\n",
    "print(f\"Records with extreme income_delta_percentage (< -100% or > 500%): {len(extreme_income)}\")\n",
    "\n",
    "# Check due principal vs credit limit\n",
    "high_due = df[df['due_principal'] > df['credit_limit']]\n",
    "print(f\"Records where due_principal > credit_limit: {len(high_due)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9742252",
   "metadata": {},
   "source": [
    "##### clean data from low quality data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "43198e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA CLEANING PROCESS\n",
      "============================================================\n",
      "Starting dataset shape: (24381, 24)\n",
      "\n",
      "1. Removing 0 duplicate rows...\n",
      "Shape after removing duplicates: (24381, 24)\n",
      "\n",
      "3. Fixing 523 extreme income delta percentages...\n",
      "Income delta percentage capped to range [-100, 500]\n",
      "\n",
      "6. Filling 21 missing values in income_delta_percentage with median (35.95)...\n",
      "\n",
      "7. Removing 756 outliers from income_delta_percentage...\n",
      "\n",
      "========================================\n",
      "CLEANING SUMMARY\n",
      "========================================\n",
      "Final dataset shape: (23625, 24)\n",
      "Records removed during cleaning: 403491\n",
      "Data quality improvement completed!\n"
     ]
    }
   ],
   "source": [
    "# Clean data from low quality data discovered in previous steps\n",
    "print(\"=\"*60)\n",
    "print(\"DATA CLEANING PROCESS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Starting dataset shape: {df.shape}\")\n",
    "\n",
    "# 1. Remove exact duplicate rows\n",
    "print(f\"\\n1. Removing {df.duplicated().sum()} duplicate rows...\")\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "print(f\"Shape after removing duplicates: {df.shape}\")\n",
    "\n",
    "# 2. Handle invalid ages (if any found in quality check)\n",
    "invalid_ages_before = len(df[(df['age'] < 18) | (df['age'] > 100)])\n",
    "if invalid_ages_before > 0:\n",
    "    print(f\"\\n2. Fixing {invalid_ages_before} invalid ages...\")\n",
    "    df['age'] = df['age'].clip(lower=18, upper=100)\n",
    "    print(f\"Ages capped to range [18, 100]\")\n",
    "\n",
    "# 3. Handle extreme income delta percentages\n",
    "extreme_income_before = len(df[(df['income_delta_percentage'] < -100) | (df['income_delta_percentage'] > 500)])\n",
    "if extreme_income_before > 0:\n",
    "    print(f\"\\n3. Fixing {extreme_income_before} extreme income delta percentages...\")\n",
    "    df['income_delta_percentage'] = df['income_delta_percentage'].clip(lower=-100, upper=500)\n",
    "    print(f\"Income delta percentage capped to range [-100, 500]\")\n",
    "\n",
    "# 4. Handle records where due_principal > credit_limit (business logic violation)\n",
    "high_due_before = len(df[df['due_principal'] > df['credit_limit']])\n",
    "if high_due_before > 0:\n",
    "    print(f\"\\n4. Fixing {high_due_before} records where due_principal > credit_limit...\")\n",
    "    # Cap due_principal to credit_limit\n",
    "    df.loc[df['due_principal'] > df['credit_limit'], 'due_principal'] = df['credit_limit']\n",
    "    print(f\"Due principal capped to credit limit for affected records\")\n",
    "\n",
    "# 5. Fill missing categorical values with 'Unknown' (if any missing values found)\n",
    "categorical_cols = ['marital_status', 'jobtitle_category', 'address_category', 'gender']\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        missing_count = df[col].isnull().sum()\n",
    "        if missing_count > 0:\n",
    "            print(f\"\\n5. Filling {missing_count} missing values in {col} with 'Unknown'...\")\n",
    "            df[col] = df[col].fillna('Unknown')\n",
    "\n",
    "# 6. Handle missing numerical values with median imputation\n",
    "numerical_cols = ['income_delta_percentage', 'age']\n",
    "for col in numerical_cols:\n",
    "    if col in df.columns:\n",
    "        missing_count = df[col].isnull().sum()\n",
    "        if missing_count > 0:\n",
    "            median_val = df[col].median()\n",
    "            print(f\"\\n6. Filling {missing_count} missing values in {col} with median ({median_val:.2f})...\")\n",
    "            df[col] = df[col].fillna(median_val)\n",
    "\n",
    "# 7. Remove outliers (values beyond 3 standard deviations) for key numerical variables\n",
    "outlier_cols = ['income_delta_percentage']\n",
    "for col in outlier_cols:\n",
    "    if col in df.columns:\n",
    "        mean_val = df[col].mean()\n",
    "        std_val = df[col].std()\n",
    "        outlier_mask = (df[col] < mean_val - 3*std_val) | (df[col] > mean_val + 3*std_val)\n",
    "        outliers_count = outlier_mask.sum()\n",
    "        if outliers_count > 0:\n",
    "            print(f\"\\n7. Removing {outliers_count} outliers from {col}...\")\n",
    "            df = df[~outlier_mask].reset_index(drop=True)\n",
    "\n",
    "print(f\"\\n\" + \"=\"*40)\n",
    "print(\"CLEANING SUMMARY\")\n",
    "print(\"=\"*40)\n",
    "print(f\"Final dataset shape: {df.shape}\")\n",
    "print(f\"Records removed during cleaning: {len(df_backup) - len(df)}\")\n",
    "print(f\"Data quality improvement completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3657c86",
   "metadata": {},
   "source": [
    "##### create target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dadc25de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TARGET VARIABLE CREATION\n",
      "============================================================\n",
      "Customer bucket distribution:\n",
      "customer_bucket\n",
      "CURRENT                      11464\n",
      "SETTLED-PAIDOFF               4395\n",
      "SETTLED                       3369\n",
      "BUCKET-1                      1731\n",
      "BUCKET-2                       843\n",
      "BUCKET-7                       805\n",
      "BUCKET-3                       379\n",
      "BUCKET-4                       271\n",
      "BUCKET-5                       201\n",
      "BUCKET-6                       130\n",
      "SETTLE-CHARGE-OFF               22\n",
      "PARTIAL-SETTLE-CHARGE-OFF       15\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Target variable distribution:\n",
      "target\n",
      "0    17407\n",
      "1     6218\n",
      "Name: count, dtype: int64\n",
      "Good customers (target=0): 17407 (73.68%)\n",
      "Bad customers (target=1): 6218 (26.32%)\n",
      "\n",
      "Good customer buckets: ['CURRENT', 'SETTLED', 'SETTLE-RESCHEDULED', 'BUCKET-1', 'BUCKET-2']\n",
      "Bad customer buckets: ['BUCKET-7', 'SETTLED-PAIDOFF', 'SETTLE-CHARGE-OFF', 'BUCKET-3', 'BUCKET-5', 'PARTIAL-SETTLE-CHARGE-OFF', 'BUCKET-4', 'BUCKET-6']\n"
     ]
    }
   ],
   "source": [
    "# Create target variable based on customer_bucket\n",
    "print(\"=\"*60)\n",
    "print(\"TARGET VARIABLE CREATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define good customer buckets\n",
    "good_buckets = ['CURRENT', 'SETTLED', 'SETTLE-RESCHEDULED', 'BUCKET-1', 'BUCKET-2']\n",
    "\n",
    "# Create target variable (0 = Good customer, 1 = Bad customer)\n",
    "df['target'] = (~df['customer_bucket'].isin(good_buckets)).astype(int)\n",
    "\n",
    "print(\"Customer bucket distribution:\")\n",
    "print(df['customer_bucket'].value_counts())\n",
    "\n",
    "print(f\"\\nTarget variable distribution:\")\n",
    "print(df['target'].value_counts())\n",
    "print(f\"Good customers (target=0): {(df['target'] == 0).sum()} ({(df['target'] == 0).mean()*100:.2f}%)\")\n",
    "print(f\"Bad customers (target=1): {(df['target'] == 1).sum()} ({(df['target'] == 1).mean()*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nGood customer buckets: {good_buckets}\")\n",
    "print(f\"Bad customer buckets: {df[df['target'] == 1]['customer_bucket'].unique().tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "02b2bb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shape: (23625, 8)\n",
      "\n",
      "Final dataset columns: ['customer_id', 'age', 'marital_status', 'income_delta_percentage', 'address_category', 'jobtitle_category', 'gender', 'target']\n",
      "\n",
      "First 5 rows of final dataset:\n",
      "   customer_id  age marital_status  income_delta_percentage address_category  \\\n",
      "0       237365   53        Married                25.515398                B   \n",
      "1       237369   40         Single                12.753936                C   \n",
      "2       237369   40         Single                12.753936                C   \n",
      "3       237461   36         Single               -21.124983                C   \n",
      "4       237493   24         Single                73.926229                A   \n",
      "\n",
      "  jobtitle_category gender  target  \n",
      "0                 D   MALE       1  \n",
      "1                 A   MALE       0  \n",
      "2                 A   MALE       0  \n",
      "3                 D   MALE       1  \n",
      "4                 D   MALE       0  \n",
      "\n",
      "Target distribution:\n",
      "target\n",
      "0    17407\n",
      "1     6218\n",
      "Name: count, dtype: int64\n",
      "Good rate: 73.68%\n",
      "Bad rate: 26.32%\n"
     ]
    }
   ],
   "source": [
    "# Create final features dataframe with target variable\n",
    "final_df = df[['customer_id', 'age', 'marital_status', 'income_delta_percentage', \n",
    "               'address_category', 'jobtitle_category', 'gender', 'target']].copy()\n",
    "\n",
    "print(\"Final dataset shape:\", final_df.shape)\n",
    "print(\"\\nFinal dataset columns:\", final_df.columns.tolist())\n",
    "print(\"\\nFirst 5 rows of final dataset:\")\n",
    "print(final_df.head())\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(final_df['target'].value_counts())\n",
    "print(f\"Good rate: {(final_df['target'] == 0).mean()*100:.2f}%\")\n",
    "print(f\"Bad rate: {(final_df['target'] == 1).mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8108caf3",
   "metadata": {},
   "source": [
    "##### save final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ce1ddc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SAVING FINAL DATASET\n",
      "============================================================\n",
      "Output directory: customer_segmentation_baked_dtree_v1.0/data\n",
      " Final dataset saved as 'customer_segmentation_baked_dtree_v1.0/data/banked_customer_segmentation_final.csv'\n",
      " Documentation saved as 'customer_segmentation_baked_dtree_v1.0/data/banked_dataset_documentation.json'\n",
      " Summary report saved as 'customer_segmentation_baked_dtree_v1.0/data/dataset_summary_report.txt'\n",
      "\n",
      "\n",
      "BANKED CUSTOMER SEGMENTATION DATASET - FINAL REPORT\n",
      "=====================================================\n",
      "\n",
      "DATASET OVERVIEW:\n",
      "- Original records: 427,116\n",
      "- Final records: 23,625\n",
      "- Records removed: 403,491 (94.5%)\n",
      "- Unique customers: 17,733\n",
      "- Features: 6 (excluding customer_id and target)\n",
      "\n",
      "TARGET DISTRIBUTION:\n",
      "- Good customers: 17,407 (73.7%)\n",
      "- Bad customers: 6,218 (26.3%)\n",
      "\n",
      "FILTERING APPLIED:\n",
      "1. Banked customers only\n",
      "2. No special programs\n",
      "3. Valid credit limits (>0)\n",
      "4. Non-null customer buckets\n",
      "5. Data quality improvements\n",
      "\n",
      "TARGET DEFINITION:\n",
      "- Good: CURRENT, SETTLED, CANCELLED, CANCELLED-PARTIAL-REFUND, SETTLE-RESCHEDULED, BUCKET-1, BUCKET-2\n",
      "- Bad: All other buckets (BUCKET-3 through BUCKET-7, charge-offs, writeoffs, etc.)\n",
      "\n",
      "FILES CREATED:\n",
      "1. banked_customer_segmentation_final.csv - Main dataset\n",
      "2. banked_dataset_documentation.json - Detailed documentation\n",
      "3. dataset_summary_report.txt - This summary\n",
      "\n",
      "Dataset is ready for customer segmentation analysis and modeling.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save final dataset with comprehensive documentation\n",
    "print(\"=\"*60)\n",
    "print(\"SAVING FINAL DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Ensure output directory exists\n",
    "import os\n",
    "import json\n",
    "out_dir = os.path.join('customer_segmentation_baked_dtree_v1.0', 'data')\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "print(f\"Output directory: {out_dir}\")\n",
    "\n",
    "# Create documentation dictionary\n",
    "documentation = {\n",
    "    \"dataset_info\": {\n",
    "        \"original_shape\": df_backup.shape,\n",
    "        \"final_shape\": final_df.shape,\n",
    "        \"records_removed\": df_backup.shape[0] - final_df.shape[0],\n",
    "        \"unique_customers\": final_df['customer_id'].nunique(),\n",
    "        \"target_distribution\": {\n",
    "            \"good_customers\": int((final_df['target'] == 0).sum()),\n",
    "            \"bad_customers\": int((final_df['target'] == 1).sum()),\n",
    "            \"good_rate_percent\": round((final_df['target'] == 0).mean()*100, 2),\n",
    "            \"bad_rate_percent\": round((final_df['target'] == 1).mean()*100, 2)\n",
    "        }\n",
    "    },\n",
    "    \"filtering_steps\": [\n",
    "        \"1. Filter for Banked customers only (limit_source == 'Banked')\",\n",
    "        \"2. Remove special program customers (special_program_flag != 'True')\", \n",
    "        \"3. Remove rank 3 and 4 customers (keep only rank 1 and 2)\",\n",
    "        \"4. Remove customers with null or zero credit_limit\",\n",
    "        \"5. Remove customers with null customer_bucket\",\n",
    "        \"6. Remove Customer with CANCELLED/CANCELLED-PARTIAL-REFUND status\",\n",
    "        \"7. Remove duplicate rows\",\n",
    "        \"8. Cap extreme values and handle outliers\",\n",
    "        \"9. Handle missing values with appropriate imputation\"\n",
    "    ],\n",
    "    \"target_definition\": {\n",
    "        \"good_customers_buckets\": ['CURRENT', 'SETTLED', 'CANCELLED', 'CANCELLED-PARTIAL-REFUND', \n",
    "                                  'SETTLE-RESCHEDULED', 'BUCKET-1', 'BUCKET-2'],\n",
    "        \"bad_customers_buckets\": \"All other customer_bucket values\",\n",
    "        \"target_encoding\": \"0 = Good customer, 1 = Bad customer\"\n",
    "    },\n",
    "    \"features_description\": {\n",
    "        \"customer_id\": \"Unique customer identifier\",\n",
    "        \"age\": \"Customer age (capped between 18-100)\",\n",
    "        \"marital_status\": \"Customer marital status\",\n",
    "        \"income_delta_percentage\": \"Income change percentage (capped between -100% to 500%)\",\n",
    "        \"address_category\": \"Address quality category (A-E)\",\n",
    "        \"jobtitle_category\": \"Job title quality category (A-E)\", \n",
    "        \"gender\": \"Customer gender (M/F)\",\n",
    "        \"target\": \"Binary target variable (0=Good, 1=Bad)\"\n",
    "    },\n",
    "    \"data_quality_summary\": {\n",
    "        \"missing_values\": \"Handled with appropriate imputation\",\n",
    "        \"duplicates\": \"Removed\",\n",
    "        \"outliers\": \"Capped extreme values\",\n",
    "        \"business_logic\": \"Validated and corrected inconsistencies\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save the final dataset\n",
    "csv_path = os.path.join(out_dir, 'banked_customer_segmentation_final.csv')\n",
    "final_df.to_csv(csv_path, index=False)\n",
    "print(f\" Final dataset saved as '{csv_path}'\")\n",
    "\n",
    "# Save documentation as JSON\n",
    "doc_path = os.path.join(out_dir, 'banked_dataset_documentation.json')\n",
    "with open(doc_path, 'w') as f:\n",
    "    json.dump(documentation, f, indent=2)\n",
    "print(f\" Documentation saved as '{doc_path}'\")\n",
    "\n",
    "# Create a summary report\n",
    "summary_report = f\"\"\"\n",
    "BANKED CUSTOMER SEGMENTATION DATASET - FINAL REPORT\n",
    "=====================================================\n",
    "\n",
    "DATASET OVERVIEW:\n",
    "- Original records: {df_backup.shape[0]:,}\n",
    "- Final records: {final_df.shape[0]:,}\n",
    "- Records removed: {df_backup.shape[0] - final_df.shape[0]:,} ({((df_backup.shape[0] - final_df.shape[0])/df_backup.shape[0]*100):.1f}%)\n",
    "- Unique customers: {final_df['customer_id'].nunique():,}\n",
    "- Features: {len(final_df.columns)-2} (excluding customer_id and target)\n",
    "\n",
    "TARGET DISTRIBUTION:\n",
    "- Good customers: {(final_df['target'] == 0).sum():,} ({(final_df['target'] == 0).mean()*100:.1f}%)\n",
    "- Bad customers: {(final_df['target'] == 1).sum():,} ({(final_df['target'] == 1).mean()*100:.1f}%)\n",
    "\n",
    "FILTERING APPLIED:\n",
    "1. Banked customers only\n",
    "2. No special programs\n",
    "3. Valid credit limits (>0)\n",
    "4. Non-null customer buckets\n",
    "5. Data quality improvements\n",
    "\n",
    "TARGET DEFINITION:\n",
    "- Good: CURRENT, SETTLED, CANCELLED, CANCELLED-PARTIAL-REFUND, SETTLE-RESCHEDULED, BUCKET-1, BUCKET-2\n",
    "- Bad: All other buckets (BUCKET-3 through BUCKET-7, charge-offs, writeoffs, etc.)\n",
    "\n",
    "FILES CREATED:\n",
    "1. banked_customer_segmentation_final.csv - Main dataset\n",
    "2. banked_dataset_documentation.json - Detailed documentation\n",
    "3. dataset_summary_report.txt - This summary\n",
    "\n",
    "Dataset is ready for customer segmentation analysis and modeling.\n",
    "\"\"\"\n",
    "\n",
    "# Save summary report\n",
    "summary_path = os.path.join(out_dir, 'dataset_summary_report.txt')\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(summary_report)\n",
    "print(f\" Summary report saved as '{summary_path}'\")\n",
    "\n",
    "# Print summary report\n",
    "print(f\"\\n{summary_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e2e545",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- Filtered to Banked customers, excluded special programs, and removed Rank 34.\n",
    "- Enforced valid credit limits and non-null customer buckets.\n",
    "- Completed data quality checks and applied targeted cleaning (duplicates, caps, imputations, and outlier handling).\n",
    "- Built a binary target from `customer_bucket` and assembled the final features.\n",
    "- Saved deliverables:\n",
    "  - `banked_customer_segmentation_final.csv`\n",
    "  - `banked_dataset_documentation.json`\n",
    "  - `dataset_summary_report.txt`\n",
    "\n",
    "Next steps (optional):\n",
    "- Explore class balance and feature distributions (EDA).\n",
    "- Train baseline models (e.g., logistic regression, tree-based).\n",
    "- Perform segmentation and stability checks across cohorts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b49b2b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f7f90d3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "credit_risk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

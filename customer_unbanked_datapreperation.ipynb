{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15ab47bf",
   "metadata": {},
   "source": [
    "# Unbanked Customer Data Preparation\n",
    "This notebook prepares the unbanked customer dataset for modeling and segmentation.\n",
    "\n",
    "It performs the following steps:\n",
    "- Load source data from `credit_report (1).xlsx`.\n",
    "- Filter to UnBanked customers and exclude special programs.\n",
    "- Remove Rank 3 and 4, enforce valid credit limits, and ensure valid customer buckets.\n",
    "- Run data quality checks (missing values, duplicates, outliers, business rules).\n",
    "- Clean data (deduplicate, cap invalid/extreme values, impute selective fields).\n",
    "- Create the binary target from `customer_bucket` (0=Good, 1=Bad).\n",
    "- Assemble the final features dataframe and save artifacts.\n",
    "\n",
    "Inputs:\n",
    "- `credit_report (1).xlsx`\n",
    "\n",
    "Outputs:\n",
    "- `unbanked_customer_segmentation_final.csv`\n",
    "- `unbanked_dataset_documentation.json`\n",
    "- `dataset_summary_report.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "648a7feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffa18241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "df = pd.read_excel(\"credit_report (1).xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4c3ec40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_backup =  df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38ca6e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>national_id</th>\n",
       "      <th>credit_limit</th>\n",
       "      <th>due_principal</th>\n",
       "      <th>customer_bucket</th>\n",
       "      <th>onboarding_merchant</th>\n",
       "      <th>first_transaction_merchant</th>\n",
       "      <th>rank</th>\n",
       "      <th>limit_source</th>\n",
       "      <th>special_program_flag</th>\n",
       "      <th>has_past_credit_flag</th>\n",
       "      <th>income_delta_percentage</th>\n",
       "      <th>income_delta_tier</th>\n",
       "      <th>income_delta_score</th>\n",
       "      <th>age</th>\n",
       "      <th>age_score</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>marital_status_score</th>\n",
       "      <th>jobtitle_category</th>\n",
       "      <th>jobtitle_score</th>\n",
       "      <th>address_category</th>\n",
       "      <th>address_score</th>\n",
       "      <th>gender</th>\n",
       "      <th>gender_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237293</td>\n",
       "      <td>28302022102615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fawry Plus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>13.1640</td>\n",
       "      <td>Married</td>\n",
       "      <td>14.6048</td>\n",
       "      <td>D</td>\n",
       "      <td>30.4325</td>\n",
       "      <td>C</td>\n",
       "      <td>23.4765</td>\n",
       "      <td>MALE</td>\n",
       "      <td>20.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>237294</td>\n",
       "      <td>28506300100399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fawry Plus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "      <td>15.5774</td>\n",
       "      <td>Married</td>\n",
       "      <td>14.6048</td>\n",
       "      <td>D</td>\n",
       "      <td>30.4325</td>\n",
       "      <td>A</td>\n",
       "      <td>17.3900</td>\n",
       "      <td>MALE</td>\n",
       "      <td>20.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>237295</td>\n",
       "      <td>25104210300141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fawry Plus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74</td>\n",
       "      <td>9.6536</td>\n",
       "      <td>Single</td>\n",
       "      <td>16.9520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>15.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>237296</td>\n",
       "      <td>29305050104961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Union Stores</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>16.3453</td>\n",
       "      <td>Married</td>\n",
       "      <td>14.6048</td>\n",
       "      <td>D</td>\n",
       "      <td>30.4325</td>\n",
       "      <td>B</td>\n",
       "      <td>19.9985</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>15.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>237297</td>\n",
       "      <td>28911010107839</td>\n",
       "      <td>5300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fawry Plus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Banked</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>67.963354</td>\n",
       "      <td>8.0</td>\n",
       "      <td>129.679634</td>\n",
       "      <td>35</td>\n",
       "      <td>16.0162</td>\n",
       "      <td>Married</td>\n",
       "      <td>14.6048</td>\n",
       "      <td>D</td>\n",
       "      <td>30.4325</td>\n",
       "      <td>C</td>\n",
       "      <td>23.4765</td>\n",
       "      <td>MALE</td>\n",
       "      <td>20.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>237298</td>\n",
       "      <td>29812152203199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Connect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>17.2229</td>\n",
       "      <td>Single</td>\n",
       "      <td>16.9520</td>\n",
       "      <td>D</td>\n",
       "      <td>30.4325</td>\n",
       "      <td>E</td>\n",
       "      <td>30.4325</td>\n",
       "      <td>MALE</td>\n",
       "      <td>20.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>237299</td>\n",
       "      <td>26708180102656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Connect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57</td>\n",
       "      <td>11.5185</td>\n",
       "      <td>Married</td>\n",
       "      <td>14.6048</td>\n",
       "      <td>D</td>\n",
       "      <td>30.4325</td>\n",
       "      <td>B</td>\n",
       "      <td>19.9985</td>\n",
       "      <td>MALE</td>\n",
       "      <td>20.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>237300</td>\n",
       "      <td>28301300100924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Connect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>13.1640</td>\n",
       "      <td>Married</td>\n",
       "      <td>14.6048</td>\n",
       "      <td>D</td>\n",
       "      <td>30.4325</td>\n",
       "      <td>D</td>\n",
       "      <td>26.9545</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>15.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>237301</td>\n",
       "      <td>29601102101092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Union Stores</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>16.8938</td>\n",
       "      <td>Married</td>\n",
       "      <td>14.6048</td>\n",
       "      <td>A</td>\n",
       "      <td>17.3900</td>\n",
       "      <td>A</td>\n",
       "      <td>17.3900</td>\n",
       "      <td>MALE</td>\n",
       "      <td>20.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>237302</td>\n",
       "      <td>28210240103117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Connect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>13.1640</td>\n",
       "      <td>Single</td>\n",
       "      <td>16.9520</td>\n",
       "      <td>D</td>\n",
       "      <td>30.4325</td>\n",
       "      <td>A</td>\n",
       "      <td>17.3900</td>\n",
       "      <td>MALE</td>\n",
       "      <td>20.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>237303</td>\n",
       "      <td>28802232200698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fawry Plus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "      <td>15.7968</td>\n",
       "      <td>Single</td>\n",
       "      <td>16.9520</td>\n",
       "      <td>A</td>\n",
       "      <td>17.3900</td>\n",
       "      <td>E</td>\n",
       "      <td>30.4325</td>\n",
       "      <td>MALE</td>\n",
       "      <td>20.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>237304</td>\n",
       "      <td>27709012105453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Star Phone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47</td>\n",
       "      <td>12.6155</td>\n",
       "      <td>Married</td>\n",
       "      <td>14.6048</td>\n",
       "      <td>D</td>\n",
       "      <td>30.4325</td>\n",
       "      <td>D</td>\n",
       "      <td>26.9545</td>\n",
       "      <td>MALE</td>\n",
       "      <td>20.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>237305</td>\n",
       "      <td>26707170200378</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SETTLED</td>\n",
       "      <td>ElShennawy</td>\n",
       "      <td>Al Masria Groub</td>\n",
       "      <td>2</td>\n",
       "      <td>UnBanked</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-18.367347</td>\n",
       "      <td>2.0</td>\n",
       "      <td>99.816327</td>\n",
       "      <td>57</td>\n",
       "      <td>11.5185</td>\n",
       "      <td>Married</td>\n",
       "      <td>14.6048</td>\n",
       "      <td>D</td>\n",
       "      <td>30.4325</td>\n",
       "      <td>B</td>\n",
       "      <td>19.9985</td>\n",
       "      <td>MALE</td>\n",
       "      <td>20.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>237305</td>\n",
       "      <td>26707170200378</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SETTLED</td>\n",
       "      <td>ElShennawy</td>\n",
       "      <td>ElShennawy</td>\n",
       "      <td>2</td>\n",
       "      <td>UnBanked</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-18.367347</td>\n",
       "      <td>2.0</td>\n",
       "      <td>99.816327</td>\n",
       "      <td>57</td>\n",
       "      <td>11.5185</td>\n",
       "      <td>Married</td>\n",
       "      <td>14.6048</td>\n",
       "      <td>D</td>\n",
       "      <td>30.4325</td>\n",
       "      <td>B</td>\n",
       "      <td>19.9985</td>\n",
       "      <td>MALE</td>\n",
       "      <td>20.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>237306</td>\n",
       "      <td>26201191900298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Select</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63</td>\n",
       "      <td>10.8603</td>\n",
       "      <td>Married</td>\n",
       "      <td>14.6048</td>\n",
       "      <td>A</td>\n",
       "      <td>17.3900</td>\n",
       "      <td>B</td>\n",
       "      <td>19.9985</td>\n",
       "      <td>MALE</td>\n",
       "      <td>20.547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    customer_id     national_id  credit_limit  due_principal customer_bucket  \\\n",
       "0        237293  28302022102615           0.0            0.0             NaN   \n",
       "1        237294  28506300100399           0.0            0.0             NaN   \n",
       "2        237295  25104210300141           0.0            0.0             NaN   \n",
       "3        237296  29305050104961           0.0            0.0             NaN   \n",
       "4        237297  28911010107839        5300.0            0.0             NaN   \n",
       "5        237298  29812152203199           0.0            0.0             NaN   \n",
       "6        237299  26708180102656           0.0            0.0             NaN   \n",
       "7        237300  28301300100924           0.0            0.0             NaN   \n",
       "8        237301  29601102101092           0.0            0.0             NaN   \n",
       "9        237302  28210240103117           0.0            0.0             NaN   \n",
       "10       237303  28802232200698           0.0            0.0             NaN   \n",
       "11       237304  27709012105453           0.0            0.0             NaN   \n",
       "12       237305  26707170200378        9000.0            0.0         SETTLED   \n",
       "13       237305  26707170200378        9000.0            0.0         SETTLED   \n",
       "14       237306  26201191900298           0.0            0.0             NaN   \n",
       "\n",
       "   onboarding_merchant first_transaction_merchant  rank limit_source  \\\n",
       "0           Fawry Plus                        NaN     3          NaN   \n",
       "1           Fawry Plus                        NaN     2          NaN   \n",
       "2           Fawry Plus                        NaN     4          NaN   \n",
       "3         Union Stores                        NaN     3          NaN   \n",
       "4           Fawry Plus                        NaN     3       Banked   \n",
       "5              Connect                        NaN     4          NaN   \n",
       "6              Connect                        NaN     2          NaN   \n",
       "7              Connect                        NaN     2          NaN   \n",
       "8         Union Stores                        NaN     1          NaN   \n",
       "9              Connect                        NaN     2          NaN   \n",
       "10          Fawry Plus                        NaN     2          NaN   \n",
       "11          Star Phone                        NaN     2          NaN   \n",
       "12          ElShennawy            Al Masria Groub     2     UnBanked   \n",
       "13          ElShennawy                 ElShennawy     2     UnBanked   \n",
       "14              Select                        NaN     1          NaN   \n",
       "\n",
       "    special_program_flag  has_past_credit_flag  income_delta_percentage  \\\n",
       "0                  False                 False                      NaN   \n",
       "1                  False                 False                      NaN   \n",
       "2                  False                 False                      NaN   \n",
       "3                  False                 False                      NaN   \n",
       "4                  False                  True                67.963354   \n",
       "5                  False                 False                      NaN   \n",
       "6                  False                 False                      NaN   \n",
       "7                  False                 False                      NaN   \n",
       "8                  False                 False                      NaN   \n",
       "9                  False                 False                      NaN   \n",
       "10                 False                 False                      NaN   \n",
       "11                 False                 False                      NaN   \n",
       "12                 False                 False               -18.367347   \n",
       "13                 False                 False               -18.367347   \n",
       "14                 False                 False                      NaN   \n",
       "\n",
       "    income_delta_tier  income_delta_score  age  age_score marital_status  \\\n",
       "0                 NaN                 NaN   42    13.1640        Married   \n",
       "1                 NaN                 NaN   39    15.5774        Married   \n",
       "2                 NaN                 NaN   74     9.6536         Single   \n",
       "3                 NaN                 NaN   32    16.3453        Married   \n",
       "4                 8.0          129.679634   35    16.0162        Married   \n",
       "5                 NaN                 NaN   26    17.2229         Single   \n",
       "6                 NaN                 NaN   57    11.5185        Married   \n",
       "7                 NaN                 NaN   42    13.1640        Married   \n",
       "8                 NaN                 NaN   29    16.8938        Married   \n",
       "9                 NaN                 NaN   42    13.1640         Single   \n",
       "10                NaN                 NaN   37    15.7968         Single   \n",
       "11                NaN                 NaN   47    12.6155        Married   \n",
       "12                2.0           99.816327   57    11.5185        Married   \n",
       "13                2.0           99.816327   57    11.5185        Married   \n",
       "14                NaN                 NaN   63    10.8603        Married   \n",
       "\n",
       "    marital_status_score jobtitle_category  jobtitle_score address_category  \\\n",
       "0                14.6048                 D         30.4325                C   \n",
       "1                14.6048                 D         30.4325                A   \n",
       "2                16.9520               NaN             NaN              NaN   \n",
       "3                14.6048                 D         30.4325                B   \n",
       "4                14.6048                 D         30.4325                C   \n",
       "5                16.9520                 D         30.4325                E   \n",
       "6                14.6048                 D         30.4325                B   \n",
       "7                14.6048                 D         30.4325                D   \n",
       "8                14.6048                 A         17.3900                A   \n",
       "9                16.9520                 D         30.4325                A   \n",
       "10               16.9520                 A         17.3900                E   \n",
       "11               14.6048                 D         30.4325                D   \n",
       "12               14.6048                 D         30.4325                B   \n",
       "13               14.6048                 D         30.4325                B   \n",
       "14               14.6048                 A         17.3900                B   \n",
       "\n",
       "    address_score  gender  gender_score  \n",
       "0         23.4765    MALE        20.547  \n",
       "1         17.3900    MALE        20.547  \n",
       "2             NaN  FEMALE        15.220  \n",
       "3         19.9985  FEMALE        15.220  \n",
       "4         23.4765    MALE        20.547  \n",
       "5         30.4325    MALE        20.547  \n",
       "6         19.9985    MALE        20.547  \n",
       "7         26.9545  FEMALE        15.220  \n",
       "8         17.3900    MALE        20.547  \n",
       "9         17.3900    MALE        20.547  \n",
       "10        30.4325    MALE        20.547  \n",
       "11        26.9545    MALE        20.547  \n",
       "12        19.9985    MALE        20.547  \n",
       "13        19.9985    MALE        20.547  \n",
       "14        19.9985    MALE        20.547  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set pandas display options to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f84a0438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (427116, 24)\n",
      "Filtered dataset shape (UnBanked only): (90017, 24)\n",
      "\n",
      "Unique values in limit_source (original):\n",
      "limit_source\n",
      "UnBanked    90017\n",
      "Banked      40939\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Filter for UnBanked customers only\n",
    "df = df[df['limit_source'] == 'UnBanked'].copy()\n",
    "print(f\"Original dataset shape: {df_backup.shape}\")\n",
    "print(f\"Filtered dataset shape (UnBanked only): {df.shape}\")\n",
    "print(f\"\\nUnique values in limit_source (original):\")\n",
    "print(df_backup['limit_source'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e62e202e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape: (90017, 24)\n",
      "\n",
      "df columns: ['customer_id', 'national_id', 'credit_limit', 'due_principal', 'customer_bucket', 'onboarding_merchant', 'first_transaction_merchant', 'rank', 'limit_source', 'special_program_flag', 'has_past_credit_flag', 'income_delta_percentage', 'income_delta_tier', 'income_delta_score', 'age', 'age_score', 'marital_status', 'marital_status_score', 'jobtitle_category', 'jobtitle_score', 'address_category', 'address_score', 'gender', 'gender_score']\n",
      "\n",
      "First 5 rows of df:\n",
      "    customer_id     national_id  credit_limit  due_principal  customer_bucket  \\\n",
      "12       237305  26707170200378        9000.0            0.0          SETTLED   \n",
      "13       237305  26707170200378        9000.0            0.0          SETTLED   \n",
      "25       237317  29101011210414       14000.0            0.0              NaN   \n",
      "26       237318  28303130100579        7000.0            0.0          CURRENT   \n",
      "32       237324  29912100100299        5600.0            0.0  SETTLED-PAIDOFF   \n",
      "\n",
      "   onboarding_merchant first_transaction_merchant  rank limit_source  \\\n",
      "12          ElShennawy            Al Masria Groub     2     UnBanked   \n",
      "13          ElShennawy                 ElShennawy     2     UnBanked   \n",
      "25   Technology Valley                        NaN     1     UnBanked   \n",
      "26   Technology Valley                   iQ Store     2     UnBanked   \n",
      "32          Fawry Plus                 Dream 2000     2     UnBanked   \n",
      "\n",
      "    special_program_flag  has_past_credit_flag  income_delta_percentage  \\\n",
      "12                 False                 False               -18.367347   \n",
      "13                 False                 False               -18.367347   \n",
      "25                 False                 False               -25.303455   \n",
      "26                 False                 False               -62.962963   \n",
      "32                 False                 False                 5.820106   \n",
      "\n",
      "    income_delta_tier  income_delta_score  age  age_score marital_status  \\\n",
      "12                2.0           99.816327   57    11.5185        Married   \n",
      "13                2.0           99.816327   57    11.5185        Married   \n",
      "25                2.0           99.746965   34    16.1259         Single   \n",
      "26                1.0           99.370370   42    13.1640        Married   \n",
      "32                4.0          100.058201   25    17.6617        Married   \n",
      "\n",
      "    marital_status_score jobtitle_category  jobtitle_score address_category  \\\n",
      "12               14.6048                 D         30.4325                B   \n",
      "13               14.6048                 D         30.4325                B   \n",
      "25               16.9520                 A         17.3900                B   \n",
      "26               14.6048                 A         17.3900                B   \n",
      "32               14.6048                 A         17.3900                D   \n",
      "\n",
      "    address_score gender  gender_score  \n",
      "12        19.9985   MALE        20.547  \n",
      "13        19.9985   MALE        20.547  \n",
      "25        19.9985   MALE        20.547  \n",
      "26        19.9985   MALE        20.547  \n",
      "32        26.9545   MALE        20.547  \n"
     ]
    }
   ],
   "source": [
    "# Filter for none special programmes\n",
    "df = df[df['special_program_flag'] != 'True'].copy()\n",
    "print(\"df shape:\", df.shape)\n",
    "print(\"\\ndf columns:\", df.columns.tolist())\n",
    "print(\"\\nFirst 5 rows of df:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "940a4915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank\n",
      "1    22241\n",
      "2    65857\n",
      "3     1801\n",
      "4      118\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unbanked rank distribution:\n",
      "Shape before removing rank 3 and 4: (90017, 24)\n",
      "Shape after removing rank 3 and 4: (88098, 24)\n"
     ]
    }
   ],
   "source": [
    "#remove UnBanked 3 and 4\n",
    "print(df['rank'].value_counts().sort_index())\n",
    "print(f\"\\nUnbanked rank distribution:\")\n",
    "print(f\"Shape before removing rank 3 and 4: {df.shape}\")\n",
    "df = df[~df['rank'].isin([3, 4])].copy()\n",
    "print(f\"Shape after removing rank 3 and 4: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4b6ca76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unbanked rank distribution:\n",
      "Shape before filtering by credit limit: (88098, 24)\n",
      "Shape after filtering by credit limit: (85875, 24)\n"
     ]
    }
   ],
   "source": [
    "# remove customers with no credit limit or credit limit = zero\n",
    "print(f\"\\nUnbanked rank distribution:\")\n",
    "print(f\"Shape before filtering by credit limit: {df.shape}\")\n",
    "df = df[df[\"credit_limit\"].notnull() & (df[\"credit_limit\"] > 0)]\n",
    "print(f\"Shape after filtering by credit limit: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db10306c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape before filtering by customer_bucket: (85875, 24)\n",
      "Shape after filtering by customer_bucket: (51909, 24)\n"
     ]
    }
   ],
   "source": [
    "# remove customers with null customer_bucket as they might got limit but no loans\n",
    "print(f\"\\nShape before filtering by customer_bucket: {df.shape}\")\n",
    "df = df[df[\"customer_bucket\"].notnull()]\n",
    "print(f\"Shape after filtering by customer_bucket: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a15d6046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove customers with CANCELLED                     1458  r\n",
    "# CANCELLED-PARTIAL-REFUND        30  r\n",
    "df = df[~df['customer_bucket'].isin(['CANCELLED', 'CANCELLED-PARTIAL-REFUND'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f6b8939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50421, 24)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9d6714",
   "metadata": {},
   "source": [
    "##### data quality check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d86748da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA QUALITY CHECK\n",
      "============================================================\n",
      "Dataset shape: (50421, 24)\n",
      "Number of unique customers: 42352\n",
      "Total records: 50421\n",
      "Average records per customer: 1.19\n"
     ]
    }
   ],
   "source": [
    "# Data Quality Check - Basic Info\n",
    "print(\"=\"*60)\n",
    "print(\"DATA QUALITY CHECK\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Number of unique customers: {df['customer_id'].nunique()}\")\n",
    "print(f\"Total records: {len(df)}\")\n",
    "print(f\"Average records per customer: {len(df) / df['customer_id'].nunique():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca67a854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "MISSING VALUES ANALYSIS\n",
      "========================================\n",
      "                         Missing_Count  Missing_Percentage\n",
      "income_delta_tier                   31            0.061482\n",
      "income_delta_score                  31            0.061482\n",
      "income_delta_percentage             31            0.061482\n"
     ]
    }
   ],
   "source": [
    "# Data Quality Check - Missing Values\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"MISSING VALUES ANALYSIS\")\n",
    "print(\"=\"*40)\n",
    "missing_summary = df.isnull().sum()\n",
    "missing_pct = (missing_summary / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing_Count': missing_summary,\n",
    "    'Missing_Percentage': missing_pct\n",
    "}).sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "print(missing_df[missing_df['Missing_Count'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b931ed0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "DUPLICATE ANALYSIS\n",
      "========================================\n",
      "Total duplicate rows: 0\n",
      "Duplicate customers (same customer_id): 8069\n",
      "Duplicate national_ids: 8069\n"
     ]
    }
   ],
   "source": [
    "# Data Quality Check - Duplicates\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"DUPLICATE ANALYSIS\")\n",
    "print(\"=\"*40)\n",
    "print(f\"Total duplicate rows: {df.duplicated().sum()}\")\n",
    "print(f\"Duplicate customers (same customer_id): {df.duplicated(subset=['customer_id']).sum()}\")\n",
    "print(f\"Duplicate national_ids: {df.duplicated(subset=['national_id']).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03431c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "CATEGORICAL VARIABLES DISTRIBUTION\n",
      "========================================\n",
      "\n",
      "CUSTOMER_BUCKET:\n",
      "customer_bucket\n",
      "CURRENT                      22616\n",
      "SETTLED                       9159\n",
      "SETTLED-PAIDOFF               6812\n",
      "BUCKET-7                      4039\n",
      "BUCKET-1                      3282\n",
      "BUCKET-2                      1597\n",
      "BUCKET-3                      1033\n",
      "BUCKET-4                       696\n",
      "BUCKET-5                       530\n",
      "BUCKET-6                       379\n",
      "PARTIAL-SETTLE-CHARGE-OFF      152\n",
      "SETTLE-CHARGE-OFF              119\n",
      "SETTLE-RESCHEDULED               6\n",
      "WRITEOFF                         1\n",
      "Name: count, dtype: int64\n",
      "Unique values: 14\n",
      "\n",
      "RANK:\n",
      "rank\n",
      "2    37822\n",
      "1    12599\n",
      "Name: count, dtype: int64\n",
      "Unique values: 2\n",
      "\n",
      "SPECIAL_PROGRAM_FLAG:\n",
      "special_program_flag\n",
      "False    49692\n",
      "True       729\n",
      "Name: count, dtype: int64\n",
      "Unique values: 2\n",
      "\n",
      "MARITAL_STATUS:\n",
      "marital_status\n",
      "Married     40087\n",
      "Single       7312\n",
      "Widowed      2159\n",
      "Divorced      863\n",
      "Name: count, dtype: int64\n",
      "Unique values: 4\n",
      "\n",
      "JOBTITLE_CATEGORY:\n",
      "jobtitle_category\n",
      "D    31035\n",
      "A    19386\n",
      "Name: count, dtype: int64\n",
      "Unique values: 2\n",
      "\n",
      "ADDRESS_CATEGORY:\n",
      "address_category\n",
      "B    22812\n",
      "A    17079\n",
      "C     7647\n",
      "D     2291\n",
      "E      592\n",
      "Name: count, dtype: int64\n",
      "Unique values: 5\n",
      "\n",
      "GENDER:\n",
      "gender\n",
      "MALE      34197\n",
      "FEMALE    16224\n",
      "Name: count, dtype: int64\n",
      "Unique values: 2\n",
      "\n",
      "INCOME_DELTA_TIER:\n",
      "income_delta_tier\n",
      "1.0     22300\n",
      "2.0      8679\n",
      "3.0      7975\n",
      "4.0      6068\n",
      "5.0      1753\n",
      "6.0      1112\n",
      "7.0       862\n",
      "8.0       761\n",
      "9.0       508\n",
      "11.0      306\n",
      "10.0       66\n",
      "Name: count, dtype: int64\n",
      "Unique values: 11\n"
     ]
    }
   ],
   "source": [
    "# Data Quality Check - Categorical Variables\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"CATEGORICAL VARIABLES DISTRIBUTION\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "categorical_cols = ['customer_bucket', 'rank', 'special_program_flag', 'marital_status', \n",
    "                   'jobtitle_category', 'address_category', 'gender', 'income_delta_tier']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        print(f\"\\n{col.upper()}:\")\n",
    "        print(df[col].value_counts())\n",
    "        print(f\"Unique values: {df[col].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a541b374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "NUMERICAL VARIABLES SUMMARY\n",
      "========================================\n",
      "       credit_limit  due_principal  income_delta_percentage           age\n",
      "count  50421.000000   50421.000000             50390.000000  50421.000000\n",
      "mean   11633.911861       7.610080               -20.106488     41.462169\n",
      "std     6314.200475      72.513928                43.819737      9.027993\n",
      "min     1100.000000       0.000000               -91.111111     21.000000\n",
      "25%     7000.000000       0.000000               -45.578231     35.000000\n",
      "50%     9500.000000       0.000000               -24.414210     41.000000\n",
      "75%    15000.000000       0.000000                -2.818270     48.000000\n",
      "max    32500.000000    2605.600000              2262.055933     64.000000\n",
      "\n",
      "========================================\n",
      "OUTLIER DETECTION (Values beyond 3 standard deviations)\n",
      "========================================\n",
      "credit_limit: 770 outliers (1.53%)\n",
      "due_principal: 641 outliers (1.27%)\n",
      "income_delta_percentage: 293 outliers (0.58%)\n",
      "age: 0 outliers (0.00%)\n"
     ]
    }
   ],
   "source": [
    "# Data Quality Check - Numerical Variables\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"NUMERICAL VARIABLES SUMMARY\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "numerical_cols = ['credit_limit', 'due_principal', 'income_delta_percentage', 'age']\n",
    "print(df[numerical_cols].describe())\n",
    "\n",
    "# Check for outliers\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"OUTLIER DETECTION (Values beyond 3 standard deviations)\")\n",
    "print(\"=\"*40)\n",
    "for col in numerical_cols:\n",
    "    if col in df.columns:\n",
    "        mean_val = df[col].mean()\n",
    "        std_val = df[col].std()\n",
    "        outliers = df[(df[col] < mean_val - 3*std_val) | (df[col] > mean_val + 3*std_val)]\n",
    "        print(f\"{col}: {len(outliers)} outliers ({len(outliers)/len(df)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6500654b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "BUSINESS LOGIC VALIDATION\n",
      "========================================\n",
      "Records with negative credit_limit: 0\n",
      "Records with invalid age (< 18 or > 100): 0\n",
      "Records with extreme income_delta_percentage (< -100% or > 500%): 28\n",
      "Records where due_principal > credit_limit: 0\n"
     ]
    }
   ],
   "source": [
    "# Data Quality Check - Business Logic Validation\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"BUSINESS LOGIC VALIDATION\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Check for negative credit limits\n",
    "negative_limits = df[df['credit_limit'] < 0]\n",
    "print(f\"Records with negative credit_limit: {len(negative_limits)}\")\n",
    "\n",
    "# Check age ranges\n",
    "invalid_ages = df[(df['age'] < 18) | (df['age'] > 100)]\n",
    "print(f\"Records with invalid age (< 18 or > 100): {len(invalid_ages)}\")\n",
    "\n",
    "# Check income delta percentage extreme values\n",
    "extreme_income = df[(df['income_delta_percentage'] < -100) | (df['income_delta_percentage'] > 500)]\n",
    "print(f\"Records with extreme income_delta_percentage (< -100% or > 500%): {len(extreme_income)}\")\n",
    "\n",
    "# Check due principal vs credit limit\n",
    "high_due = df[df['due_principal'] > df['credit_limit']]\n",
    "print(f\"Records where due_principal > credit_limit: {len(high_due)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9742252",
   "metadata": {},
   "source": [
    "##### clean data form low quality data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43198e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA CLEANING PROCESS\n",
      "============================================================\n",
      "Starting dataset shape: (50421, 24)\n",
      "\n",
      "1. Removing 0 duplicate rows...\n",
      "\n",
      "1. Removing 0 duplicate rows...\n",
      "Shape after removing duplicates: (50421, 24)\n",
      "\n",
      "3. Fixing 28 extreme income delta percentages...\n",
      "Income delta percentage capped to range [-100, 500]\n",
      "\n",
      "6. Filling 31 missing values in income_delta_percentage with median (-24.41)...\n",
      "\n",
      "7. Removing 330 outliers from income_delta_percentage...\n",
      "\n",
      "========================================\n",
      "CLEANING SUMMARY\n",
      "========================================\n",
      "Final dataset shape: (50091, 24)\n",
      "Records removed during cleaning: 377025\n",
      "Data quality improvement completed!\n",
      "Shape after removing duplicates: (50421, 24)\n",
      "\n",
      "3. Fixing 28 extreme income delta percentages...\n",
      "Income delta percentage capped to range [-100, 500]\n",
      "\n",
      "6. Filling 31 missing values in income_delta_percentage with median (-24.41)...\n",
      "\n",
      "7. Removing 330 outliers from income_delta_percentage...\n",
      "\n",
      "========================================\n",
      "CLEANING SUMMARY\n",
      "========================================\n",
      "Final dataset shape: (50091, 24)\n",
      "Records removed during cleaning: 377025\n",
      "Data quality improvement completed!\n"
     ]
    }
   ],
   "source": [
    "# Clean data from low quality data discovered in previous steps\n",
    "print(\"=\"*60)\n",
    "print(\"DATA CLEANING PROCESS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Starting dataset shape: {df.shape}\")\n",
    "\n",
    "# 1. Remove exact duplicate rows\n",
    "print(f\"\\n1. Removing {df.duplicated().sum()} duplicate rows...\")\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "print(f\"Shape after removing duplicates: {df.shape}\")\n",
    "\n",
    "# 2. Handle invalid ages (if any found in quality check)\n",
    "invalid_ages_before = len(df[(df['age'] < 18) | (df['age'] > 100)])\n",
    "if invalid_ages_before > 0:\n",
    "    print(f\"\\n2. Fixing {invalid_ages_before} invalid ages...\")\n",
    "    df['age'] = df['age'].clip(lower=18, upper=100)\n",
    "    print(f\"Ages capped to range [18, 100]\")\n",
    "\n",
    "# 3. Handle extreme income delta percentages\n",
    "extreme_income_before = len(df[(df['income_delta_percentage'] < -100) | (df['income_delta_percentage'] > 500)])\n",
    "if extreme_income_before > 0:\n",
    "    print(f\"\\n3. Fixing {extreme_income_before} extreme income delta percentages...\")\n",
    "    df['income_delta_percentage'] = df['income_delta_percentage'].clip(lower=-100, upper=500)\n",
    "    print(f\"Income delta percentage capped to range [-100, 500]\")\n",
    "\n",
    "# 4. Handle records where due_principal > credit_limit (business logic violation)\n",
    "high_due_before = len(df[df['due_principal'] > df['credit_limit']])\n",
    "if high_due_before > 0:\n",
    "    print(f\"\\n4. Fixing {high_due_before} records where due_principal > credit_limit...\")\n",
    "    # Cap due_principal to credit_limit\n",
    "    df.loc[df['due_principal'] > df['credit_limit'], 'due_principal'] = df['credit_limit']\n",
    "    print(f\"Due principal capped to credit limit for affected records\")\n",
    "\n",
    "# 5. Fill missing categorical values with 'Unknown' (if any missing values found)\n",
    "categorical_cols = ['marital_status', 'jobtitle_category', 'address_category', 'gender']\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        missing_count = df[col].isnull().sum()\n",
    "        if missing_count > 0:\n",
    "            print(f\"\\n5. Filling {missing_count} missing values in {col} with 'Unknown'...\")\n",
    "            df[col] = df[col].fillna('Unknown')\n",
    "\n",
    "# 6. Handle missing numerical values with median imputation\n",
    "numerical_cols = ['income_delta_percentage', 'age']\n",
    "for col in numerical_cols:\n",
    "    if col in df.columns:\n",
    "        missing_count = df[col].isnull().sum()\n",
    "        if missing_count > 0:\n",
    "            median_val = df[col].median()\n",
    "            print(f\"\\n6. Filling {missing_count} missing values in {col} with median ({median_val:.2f})...\")\n",
    "            df[col] = df[col].fillna(median_val)\n",
    "\n",
    "# 7. Remove outliers (values beyond 3 standard deviations) for key numerical variables\n",
    "outlier_cols = ['income_delta_percentage']\n",
    "for col in outlier_cols:\n",
    "    if col in df.columns:\n",
    "        mean_val = df[col].mean()\n",
    "        std_val = df[col].std()\n",
    "        outlier_mask = (df[col] < mean_val - 3*std_val) | (df[col] > mean_val + 3*std_val)\n",
    "        outliers_count = outlier_mask.sum()\n",
    "        if outliers_count > 0:\n",
    "            print(f\"\\n7. Removing {outliers_count} outliers from {col}...\")\n",
    "            df = df[~outlier_mask].reset_index(drop=True)\n",
    "\n",
    "print(f\"\\n\" + \"=\"*40)\n",
    "print(\"CLEANING SUMMARY\")\n",
    "print(\"=\"*40)\n",
    "print(f\"Final dataset shape: {df.shape}\")\n",
    "print(f\"Records removed during cleaning: {len(df_backup) - len(df)}\")\n",
    "print(f\"Data quality improvement completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3657c86",
   "metadata": {},
   "source": [
    "##### create target variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dadc25de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TARGET VARIABLE CREATION\n",
      "============================================================\n",
      "Customer bucket distribution:\n",
      "customer_bucket\n",
      "CURRENT                      22510\n",
      "SETTLED                       9095\n",
      "SETTLED-PAIDOFF               6737\n",
      "BUCKET-7                      4018\n",
      "BUCKET-1                      3261\n",
      "BUCKET-2                      1582\n",
      "BUCKET-3                      1026\n",
      "BUCKET-4                       686\n",
      "BUCKET-5                       524\n",
      "BUCKET-6                       378\n",
      "PARTIAL-SETTLE-CHARGE-OFF      150\n",
      "SETTLE-CHARGE-OFF              117\n",
      "SETTLE-RESCHEDULED               6\n",
      "WRITEOFF                         1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Target variable distribution:\n",
      "target\n",
      "0    43185\n",
      "1     6906\n",
      "Name: count, dtype: int64\n",
      "Good customers (target=0): 43185 (86.21%)\n",
      "Bad customers (target=1): 6906 (13.79%)\n",
      "\n",
      "Good customer buckets: ['CURRENT', 'SETTLED', 'SETTLED-PAIDOFF', 'BUCKET-1', 'BUCKET-2']\n",
      "Bad customer buckets: ['BUCKET-7', 'PARTIAL-SETTLE-CHARGE-OFF', 'BUCKET-5', 'BUCKET-6', 'BUCKET-4', 'SETTLE-CHARGE-OFF', 'BUCKET-3', 'SETTLE-RESCHEDULED', 'WRITEOFF']\n",
      "customer_bucket\n",
      "CURRENT                      22510\n",
      "SETTLED                       9095\n",
      "SETTLED-PAIDOFF               6737\n",
      "BUCKET-7                      4018\n",
      "BUCKET-1                      3261\n",
      "BUCKET-2                      1582\n",
      "BUCKET-3                      1026\n",
      "BUCKET-4                       686\n",
      "BUCKET-5                       524\n",
      "BUCKET-6                       378\n",
      "PARTIAL-SETTLE-CHARGE-OFF      150\n",
      "SETTLE-CHARGE-OFF              117\n",
      "SETTLE-RESCHEDULED               6\n",
      "WRITEOFF                         1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Target variable distribution:\n",
      "target\n",
      "0    43185\n",
      "1     6906\n",
      "Name: count, dtype: int64\n",
      "Good customers (target=0): 43185 (86.21%)\n",
      "Bad customers (target=1): 6906 (13.79%)\n",
      "\n",
      "Good customer buckets: ['CURRENT', 'SETTLED', 'SETTLED-PAIDOFF', 'BUCKET-1', 'BUCKET-2']\n",
      "Bad customer buckets: ['BUCKET-7', 'PARTIAL-SETTLE-CHARGE-OFF', 'BUCKET-5', 'BUCKET-6', 'BUCKET-4', 'SETTLE-CHARGE-OFF', 'BUCKET-3', 'SETTLE-RESCHEDULED', 'WRITEOFF']\n"
     ]
    }
   ],
   "source": [
    "# Create target variable based on customer_bucket\n",
    "print(\"=\"*60)\n",
    "print(\"TARGET VARIABLE CREATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define good customer buckets\n",
    "good_buckets = ['CURRENT', 'SETTLED', 'SETTLED-PAIDOFF', 'BUCKET-1', 'BUCKET-2']\n",
    "\n",
    "# Create target variable (0 = Good customer, 1 = Bad customer)\n",
    "df['target'] = (~df['customer_bucket'].isin(good_buckets)).astype(int)\n",
    "\n",
    "print(\"Customer bucket distribution:\")\n",
    "print(df['customer_bucket'].value_counts())\n",
    "\n",
    "print(f\"\\nTarget variable distribution:\")\n",
    "print(df['target'].value_counts())\n",
    "print(f\"Good customers (target=0): {(df['target'] == 0).sum()} ({(df['target'] == 0).mean()*100:.2f}%)\")\n",
    "print(f\"Bad customers (target=1): {(df['target'] == 1).sum()} ({(df['target'] == 1).mean()*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nGood customer buckets: {good_buckets}\")\n",
    "print(f\"Bad customer buckets: {df[df['target'] == 1]['customer_bucket'].unique().tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02b2bb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shape: (50091, 8)\n",
      "\n",
      "Final dataset columns: ['customer_id', 'age', 'marital_status', 'income_delta_percentage', 'address_category', 'jobtitle_category', 'gender', 'target']\n",
      "\n",
      "First 5 rows of final dataset:\n",
      "   customer_id  age marital_status  income_delta_percentage address_category  \\\n",
      "0       237305   57        Married               -18.367347                B   \n",
      "1       237305   57        Married               -18.367347                B   \n",
      "2       237318   42        Married               -62.962963                B   \n",
      "3       237324   25        Married                 5.820106                D   \n",
      "4       237324   25        Married                 5.820106                D   \n",
      "\n",
      "  jobtitle_category gender  target  \n",
      "0                 D   MALE       0  \n",
      "1                 D   MALE       0  \n",
      "2                 A   MALE       0  \n",
      "3                 A   MALE       0  \n",
      "4                 A   MALE       0  \n",
      "\n",
      "Target distribution:\n",
      "target\n",
      "0    43185\n",
      "1     6906\n",
      "Name: count, dtype: int64\n",
      "Good rate: 86.21%\n",
      "Bad rate: 13.79%\n"
     ]
    }
   ],
   "source": [
    "# Create final features dataframe with target variable\n",
    "final_df = df[['customer_id', 'age', 'marital_status', 'income_delta_percentage', \n",
    "               'address_category', 'jobtitle_category', 'gender', 'target']].copy()\n",
    "\n",
    "print(\"Final dataset shape:\", final_df.shape)\n",
    "print(\"\\nFinal dataset columns:\", final_df.columns.tolist())\n",
    "print(\"\\nFirst 5 rows of final dataset:\")\n",
    "print(final_df.head())\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(final_df['target'].value_counts())\n",
    "print(f\"Good rate: {(final_df['target'] == 0).mean()*100:.2f}%\")\n",
    "print(f\"Bad rate: {(final_df['target'] == 1).mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8108caf3",
   "metadata": {},
   "source": [
    "##### save final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce1ddc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SAVING FINAL DATASET\n",
      "============================================================\n",
      "Output directory: customer_segmantation_unbaked_dtree_v1.0/data\n",
      " Final dataset saved as 'customer_segmantation_unbaked_dtree_v1.0/data/unbanked_customer_segmentation_final.csv'\n",
      " Documentation saved as 'customer_segmantation_unbaked_dtree_v1.0/data/unbanked_dataset_documentation.json'\n",
      " Summary report saved as 'customer_segmantation_unbaked_dtree_v1.0/data/dataset_summary_report.txt'\n",
      "\n",
      "\n",
      "UNBANKED CUSTOMER SEGMENTATION DATASET - FINAL REPORT\n",
      "=====================================================\n",
      "\n",
      "DATASET OVERVIEW:\n",
      "- Original records: 427,116\n",
      "- Final records: 50,091\n",
      "- Records removed: 377,025 (88.3%)\n",
      "- Unique customers: 42,100\n",
      "- Features: 6 (excluding customer_id and target)\n",
      "\n",
      "TARGET DISTRIBUTION:\n",
      "- Good customers: 43,185 (86.2%)\n",
      "- Bad customers: 6,906 (13.8%)\n",
      "\n",
      "FILTERING APPLIED:\n",
      "1. UnBanked customers only\n",
      "2. No special programs\n",
      "3. Rank 1-2 only (removed 3-4)\n",
      "4. Valid credit limits (>0)\n",
      "5. Non-null customer buckets\n",
      "6. Data quality improvements\n",
      "\n",
      "TARGET DEFINITION:\n",
      "- Good: CURRENT, SETTLED, CANCELLED, CANCELLED-PARTIAL-REFUND, SETTLE-RESCHEDULED, BUCKET-1, BUCKET-2\n",
      "- Bad: All other buckets (BUCKET-3 through BUCKET-7, charge-offs, writeoffs, etc.)\n",
      "\n",
      "FILES CREATED:\n",
      "1. unbanked_customer_segmentation_final.csv - Main dataset\n",
      "2. unbanked_dataset_documentation.json - Detailed documentation\n",
      "3. dataset_summary_report.txt - This summary\n",
      "\n",
      "Dataset is ready for customer segmentation analysis and modeling.\n",
      "\n",
      " Final dataset saved as 'customer_segmantation_unbaked_dtree_v1.0/data/unbanked_customer_segmentation_final.csv'\n",
      " Documentation saved as 'customer_segmantation_unbaked_dtree_v1.0/data/unbanked_dataset_documentation.json'\n",
      " Summary report saved as 'customer_segmantation_unbaked_dtree_v1.0/data/dataset_summary_report.txt'\n",
      "\n",
      "\n",
      "UNBANKED CUSTOMER SEGMENTATION DATASET - FINAL REPORT\n",
      "=====================================================\n",
      "\n",
      "DATASET OVERVIEW:\n",
      "- Original records: 427,116\n",
      "- Final records: 50,091\n",
      "- Records removed: 377,025 (88.3%)\n",
      "- Unique customers: 42,100\n",
      "- Features: 6 (excluding customer_id and target)\n",
      "\n",
      "TARGET DISTRIBUTION:\n",
      "- Good customers: 43,185 (86.2%)\n",
      "- Bad customers: 6,906 (13.8%)\n",
      "\n",
      "FILTERING APPLIED:\n",
      "1. UnBanked customers only\n",
      "2. No special programs\n",
      "3. Rank 1-2 only (removed 3-4)\n",
      "4. Valid credit limits (>0)\n",
      "5. Non-null customer buckets\n",
      "6. Data quality improvements\n",
      "\n",
      "TARGET DEFINITION:\n",
      "- Good: CURRENT, SETTLED, CANCELLED, CANCELLED-PARTIAL-REFUND, SETTLE-RESCHEDULED, BUCKET-1, BUCKET-2\n",
      "- Bad: All other buckets (BUCKET-3 through BUCKET-7, charge-offs, writeoffs, etc.)\n",
      "\n",
      "FILES CREATED:\n",
      "1. unbanked_customer_segmentation_final.csv - Main dataset\n",
      "2. unbanked_dataset_documentation.json - Detailed documentation\n",
      "3. dataset_summary_report.txt - This summary\n",
      "\n",
      "Dataset is ready for customer segmentation analysis and modeling.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save final dataset with comprehensive documentation\n",
    "print(\"=\"*60)\n",
    "print(\"SAVING FINAL DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Ensure output directory exists\n",
    "import os\n",
    "import json\n",
    "out_dir = os.path.join('customer_segmantation_unbaked_dtree_v1.0', 'data')\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "print(f\"Output directory: {out_dir}\")\n",
    "\n",
    "# Create documentation dictionary\n",
    "documentation = {\n",
    "    \"dataset_info\": {\n",
    "        \"original_shape\": df_backup.shape,\n",
    "        \"final_shape\": final_df.shape,\n",
    "        \"records_removed\": df_backup.shape[0] - final_df.shape[0],\n",
    "        \"unique_customers\": final_df['customer_id'].nunique(),\n",
    "        \"target_distribution\": {\n",
    "            \"good_customers\": int((final_df['target'] == 0).sum()),\n",
    "            \"bad_customers\": int((final_df['target'] == 1).sum()),\n",
    "            \"good_rate_percent\": round((final_df['target'] == 0).mean()*100, 2),\n",
    "            \"bad_rate_percent\": round((final_df['target'] == 1).mean()*100, 2)\n",
    "        }\n",
    "    },\n",
    "    \"filtering_steps\": [\n",
    "        \"1. Filter for UnBanked customers only (limit_source == 'UnBanked')\",\n",
    "        \"2. Remove special program customers (special_program_flag != 'True')\", \n",
    "        \"3. Remove rank 3 and 4 customers (keep only rank 1 and 2)\",\n",
    "        \"4. Remove customers with null or zero credit_limit\",\n",
    "        \"5. Remove customers with null customer_bucket\",\n",
    "        \"6. Remove duplicate rows\",\n",
    "        \"7. Cap extreme values and handle outliers\",\n",
    "        \"8. Handle missing values with appropriate imputation\"\n",
    "    ],\n",
    "    \"target_definition\": {\n",
    "        \"good_customers_buckets\": ['CURRENT', 'SETTLED', 'CANCELLED', 'CANCELLED-PARTIAL-REFUND', \n",
    "                                  'SETTLE-RESCHEDULED', 'BUCKET-1', 'BUCKET-2'],\n",
    "        \"bad_customers_buckets\": \"All other customer_bucket values\",\n",
    "        \"target_encoding\": \"0 = Good customer, 1 = Bad customer\"\n",
    "    },\n",
    "    \"features_description\": {\n",
    "        \"customer_id\": \"Unique customer identifier\",\n",
    "        \"age\": \"Customer age (capped between 18-100)\",\n",
    "        \"marital_status\": \"Customer marital status\",\n",
    "        \"income_delta_percentage\": \"Income change percentage (capped between -100% to 500%)\",\n",
    "        \"address_category\": \"Address quality category (A-E)\",\n",
    "        \"jobtitle_category\": \"Job title quality category (A-E)\", \n",
    "        \"gender\": \"Customer gender (M/F)\",\n",
    "        \"target\": \"Binary target variable (0=Good, 1=Bad)\"\n",
    "    },\n",
    "    \"data_quality_summary\": {\n",
    "        \"missing_values\": \"Handled with appropriate imputation\",\n",
    "        \"duplicates\": \"Removed\",\n",
    "        \"outliers\": \"Capped extreme values\",\n",
    "        \"business_logic\": \"Validated and corrected inconsistencies\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save the final dataset\n",
    "csv_path = os.path.join(out_dir, 'unbanked_customer_segmentation_final.csv')\n",
    "final_df.to_csv(csv_path, index=False)\n",
    "print(f\" Final dataset saved as '{csv_path}'\")\n",
    "\n",
    "# Save documentation as JSON\n",
    "doc_path = os.path.join(out_dir, 'unbanked_dataset_documentation.json')\n",
    "with open(doc_path, 'w') as f:\n",
    "    json.dump(documentation, f, indent=2)\n",
    "print(f\" Documentation saved as '{doc_path}'\")\n",
    "\n",
    "# Create a summary report\n",
    "summary_report = f\"\"\"\n",
    "UNBANKED CUSTOMER SEGMENTATION DATASET - FINAL REPORT\n",
    "=====================================================\n",
    "\n",
    "DATASET OVERVIEW:\n",
    "- Original records: {df_backup.shape[0]:,}\n",
    "- Final records: {final_df.shape[0]:,}\n",
    "- Records removed: {df_backup.shape[0] - final_df.shape[0]:,} ({((df_backup.shape[0] - final_df.shape[0])/df_backup.shape[0]*100):.1f}%)\n",
    "- Unique customers: {final_df['customer_id'].nunique():,}\n",
    "- Features: {len(final_df.columns)-2} (excluding customer_id and target)\n",
    "\n",
    "TARGET DISTRIBUTION:\n",
    "- Good customers: {(final_df['target'] == 0).sum():,} ({(final_df['target'] == 0).mean()*100:.1f}%)\n",
    "- Bad customers: {(final_df['target'] == 1).sum():,} ({(final_df['target'] == 1).mean()*100:.1f}%)\n",
    "\n",
    "FILTERING APPLIED:\n",
    "1. UnBanked customers only\n",
    "2. No special programs\n",
    "3. Rank 1-2 only (removed 3-4)\n",
    "4. Valid credit limits (>0)\n",
    "5. Non-null customer buckets\n",
    "6. Data quality improvements\n",
    "\n",
    "TARGET DEFINITION:\n",
    "- Good: CURRENT, SETTLED, CANCELLED, CANCELLED-PARTIAL-REFUND, SETTLE-RESCHEDULED, BUCKET-1, BUCKET-2\n",
    "- Bad: All other buckets (BUCKET-3 through BUCKET-7, charge-offs, writeoffs, etc.)\n",
    "\n",
    "FILES CREATED:\n",
    "1. unbanked_customer_segmentation_final.csv - Main dataset\n",
    "2. unbanked_dataset_documentation.json - Detailed documentation\n",
    "3. dataset_summary_report.txt - This summary\n",
    "\n",
    "Dataset is ready for customer segmentation analysis and modeling.\n",
    "\"\"\"\n",
    "\n",
    "# Save summary report\n",
    "summary_path = os.path.join(out_dir, 'dataset_summary_report.txt')\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(summary_report)\n",
    "print(f\" Summary report saved as '{summary_path}'\")\n",
    "\n",
    "# Print summary report\n",
    "print(f\"\\n{summary_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e2e545",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- Filtered to UnBanked customers, excluded special programs, and removed Rank 34.\n",
    "- Enforced valid credit limits and non-null customer buckets.\n",
    "- Completed data quality checks and applied targeted cleaning (duplicates, caps, imputations, and outlier handling).\n",
    "- Built a binary target from `customer_bucket` and assembled the final features.\n",
    "- Saved deliverables:\n",
    "  - `unbanked_customer_segmentation_final.csv`\n",
    "  - `unbanked_dataset_documentation.json`\n",
    "  - `dataset_summary_report.txt`\n",
    "\n",
    "Next steps (optional):\n",
    "- Explore class balance and feature distributions (EDA).\n",
    "- Train baseline models (e.g., logistic regression, tree-based).\n",
    "- Perform segmentation and stability checks across cohorts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b49b2b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "credit_risk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
